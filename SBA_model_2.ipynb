{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitatoin Learning 모델 2\n",
    "---\n",
    "## Description\n",
    "> Behavioral Cloning 방식을 넘어 Data Aggregation 방식 도입.\n",
    "\n",
    "* 실제 로봇과 상호작용 필요\n",
    "* model v_1 과 다른 구조 필요\n",
    "* \n",
    "\n",
    "## todo\n",
    "* [ ] OpenAI gym like style\n",
    "* [ ] 학습데이터 로컬에 파일로 save & load\n",
    "* [ ] 학습에 사용된 원본(color) 데이터도 따로 저장하기\n",
    "* [ ] 터틀봇과 데이터 송수신하기 - python 라이브러리 형태로 ros topic 에 접근이 가능한가? 되면 바로 python 레벨에서 통신가능\n",
    "* [ ] jupyter 버전 / terminal 스크립트 버전 둘 다 돌아가게 만들기\n",
    "\n",
    "## Issue\n",
    "* jupyter 에서는 non-blocking keyboard 입력이 어려운 듯\n",
    "* 그래서 그냥 스크립트로 터미널에서 돌려야 할 듯\n",
    "* 그리고 linux 에서는 termios 모듈을 써야하고 windows 에서는 msvcrt 모듈을 써야함!!\n",
    "\n",
    "## 터틀봇 컨트롤\n",
    "[키보드 제어 링크](http://emanual.robotis.com/docs/en/platform/turtlebot3/teleoperation/#keyboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 당신의 os 는 Windows 입니다.\n"
     ]
    }
   ],
   "source": [
    "os_cur = platform.system() # 현재 os 시스템 정보 # 윈도우 or 리눅스\n",
    "print('> 당신의 os 는 {} 입니다.'.format(os_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, database, model, sess):\n",
    "        self.database = database # 외부에 학습데이터 저장해놓기. 데이터는 소중하니까\n",
    "        self.model = model # CNN 모델\n",
    "        self.sess = sess # session 객체\n",
    "        print('> Env 생성')\n",
    "    \n",
    "    def reset(self, image, ridar=None):\n",
    "        # 터틀봇으로부터 카메라 데이터 및 라이다 데이터를 수신하여 반환하는 메서드\n",
    "        # 동시에 초기화\n",
    "        # ** 통신필요 **\n",
    "        # recv 함수들 모두 인자 수정해야함!!\n",
    "        observation = image\n",
    "        print('> Env started!')\n",
    "        return observation\n",
    "    \n",
    "    def pause(self):\n",
    "        # 주행을 멈춘다.\n",
    "        # for learning or exit\n",
    "        pass\n",
    "    \n",
    "    def recv_data(self, image, ridar=None):\n",
    "        # 터틀봇으로부터 카메라 데이터 및 라이다 데이터를 수신하여 반환하는 메서드\n",
    "        # ** 통신필요 **\n",
    "        observation = image\n",
    "        return observation\n",
    "    \n",
    "    def recv_command_fromhuman(self):\n",
    "        # human 이 수동으로 조종한 데이터를 수신하여 반환하는 메서드\n",
    "        # 단순히 기능으로 판단\n",
    "        \n",
    "        key = getkey() # 키보드 입력 없을 때 return 이 None 인지???\n",
    "        if(key): # key - val mapping, require nonzero\n",
    "            print('- [debug] human 이 조종함. {}'.format(key))\n",
    "            val = key\n",
    "            return val\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def convert_to_command(self, key):\n",
    "        command = np.array(lend(label))\n",
    "        command[key] = 1\n",
    "        return command\n",
    "    \n",
    "    def send_data(self, policy):\n",
    "        # 터틀봇에 policy 즉, action command 를 보내는 메서드\n",
    "        # ** 통신필요 **\n",
    "        try:\n",
    "            pass\n",
    "        except:\n",
    "            # 에러 메시지 띄우고 프로그램 종료\n",
    "            pass\n",
    "        \n",
    "        return action        \n",
    "    \n",
    "    def get_dataset(self, observation, label):\n",
    "        # 외부 데이터베이스에 현재상태에 대한 데이터를 제공하기위한 메서드\n",
    "        return observation, label\n",
    "    \n",
    "    def step(self, processed):\n",
    "        # 메인 루프.\n",
    "        # 영상획득 - 전처리(외부로부터 진행) - 개입여부 확인 - 개입했다면 데이터 추가하고 개입한대로 action 수행\n",
    "        #                                   - 아니라면 도출된 policy 결과로 action 수행\n",
    "      \n",
    "        self.send_data(action) # 터틀봇에 action 을 송신한다.\n",
    "        \n",
    "        image_original = self.recv_data(0)\n",
    "        return image_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CVHelper:\n",
    "    # openCV 작업만 하는 class\n",
    "    def __init__(self):\n",
    "        print('> CVHelper 생성')\n",
    "    \n",
    "    def preprocess_frame(self, frame):\n",
    "        # 전처리 한 frame 을 반환해줌\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret_bin, binary = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        if(ret_bin):\n",
    "            return binary\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def origin_to_obs(self, video_file, label_file=None):\n",
    "        # 원본 이미지파일 --> 전처리된 학습데이터\n",
    "        # 를 우선 txt 파일로 저장\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        width, height = cap.get(3), cap.get(4) # w, h\n",
    "        tmp_data = []\n",
    "        tmp_label = label_file\n",
    "        print('> 학습데이터 생성 중 - {}..'.format(data_base.name))\n",
    "        \n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if(ret):\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                ret_bin, binary = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)\n",
    "                tmp_data.append(binary)\n",
    "        \n",
    "        data_base = h5py.File('train_data.h5', 'w') # 파일에 저장, 최초 생성\n",
    "        data_base.create_dataset('image', data=tmp_data, dtype='float32')\n",
    "        data_base.create_dataset('label', data=tmp_label, dtype='float32')\n",
    "        data_base.close()\n",
    "        \n",
    "        print('> 학습데이터 생성 완료 - {}..'.format(data_base.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, h, w, sess):\n",
    "        self.size_h = h\n",
    "        self.size_w = w\n",
    "        self.sess = sess\n",
    "        self.model = self.make_model()\n",
    "    \n",
    "    def make_model(self):\n",
    "        # 모델\n",
    "        self.observation = tf.placeholder(shape=[None, self.size_h, self.size_w, 1], dtype=tf.float32) # 이미지 데이터\n",
    "        self.label = tf.placeholder(shape=[None, 3], dtype=tf.int16) # 라벨 데이터\n",
    "        \n",
    "        self.w_in = tf.Variable(tf.random_normal([5,5,1,8], stddev=.01)) # conv 1 가중치\n",
    "        self.l1 = tf.nn.conv2d(self.observation, self.w_in, strides=[1,1,1,1], padding='SAME')\n",
    "        self.l1 = tf.nn.relu(self.l1)\n",
    "        self.l1 = tf.nn.max_pool(self.l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        self.w_out = tf.Variable(tf.random_normal(shape=[self.size_w//2*self.size_h//2*8, 3], stddev=.01))\n",
    "        self.b = tf.Variable(tf.random_normal([3]))\n",
    "        self.h_flat = tf.reshape(self.l1, [-1, self.size_w//2*self.size_h//2*8])\n",
    "        \n",
    "        self.output = tf.matmul(self.h_flat, self.w_out) + self.b\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.output, labels=self.label))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(self.cost)\n",
    "        print('> 모델 생성 완료')\n",
    "        \n",
    "    def train(self, batch_in, batch_label):\n",
    "        # 학습시행.\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict={self.observation:batch_in, self.label:batch_label})\n",
    "        return cost\n",
    "    \n",
    "    def policy(self, input_data):\n",
    "        # policy 만 도출하기\n",
    "        output = self.sess.run(self.output, feed_dict={self.observation:input_data})\n",
    "        return output\n",
    "    \n",
    "    def test(self, in_test, label_test):\n",
    "        # 길을 잘 인식하는지 테스트.\n",
    "        # 테스트 데이터 셋을 미리 저장해놓고 검증하는 메서드\n",
    "        in_test_copied = copy.deepcopy(in_test)\n",
    "        cnt = 0\n",
    "        for step in range(len(in_test_copied)):\n",
    "            key = cv2.waitKey(10) & 0xFF\n",
    "            if(key == ord('q')):\n",
    "                break\n",
    "            out = self.sess.run(self.output, feed_dict={self.observation:in_test_copied[step:step+1]})\n",
    "            idx = np.argmax(out, axis=1)\n",
    "            one_hot = np.zeros_like(out)\n",
    "            one_hot[0][idx[0]] = 1\n",
    "            '''if(np.all(one_hot == label_test[])):\n",
    "                cnt += 1'''\n",
    "            cv2.putText(in_test_copied[step], 'command : {}'.format(one_hot[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX, .3, (0,0,255), 1)\n",
    "            cv2.imshow('testing..', in_test_copied[step])\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        accuracy = cnt / len(in_test)\n",
    "        print('acc :', accuracy)\n",
    "    \n",
    "    def test_live(self):\n",
    "        # 실시간으로 길을 잘 인식하는지 테스트하는 메서드.\n",
    "        out = self.sess.run(self.output, feed_dict={self.observation:d})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Env 생성\n",
      "> CVHelper 생성\n",
      "> 학습데이터 생성 중 - data.txt..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-84507ca4c698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCVHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin_to_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-36f2bcd7e99e>\u001b[0m in \u001b[0;36morigin_to_obs\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'> 학습데이터 생성 중 - {}..'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = Env(None,None,None)\n",
    "helper = CVHelper()\n",
    "helper.origin_to_obs('test.txt') # 원본으로부터 학습데이터 파일로 생성\n",
    "\n",
    "with h5py.File('train_data.h5', 'r') as f: # binary 파일로 학습데이터 다루기\n",
    "    batch_in = f['image']\n",
    "    batch_label = f['label']\n",
    "    print('> 사전학습 데이터 load & setting 완료')\n",
    "    \n",
    "width = 100\n",
    "height = 100\n",
    "total_epoch = 1\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 모델 생성 완료\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'Placeholder_12:0', which has shape '(?, 100, 100, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9893e28c4618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{} epoch, cost : {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-d799f3f0859d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_in, batch_label)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# 학습시행.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'Placeholder_12:0', which has shape '(?, 100, 100, 1)'"
     ]
    }
   ],
   "source": [
    "# 사전학습하기\n",
    "# 우선 터틀봇을 조종하며 얻은 영상과 라벨 데이터로 CNN 사전학습하기.\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    model = CNN(width, height, sess)\n",
    "    sess.run(init)\n",
    "    print('> 사전 학습 중..')\n",
    "    for epoch in range(total_epoch):\n",
    "        cost = model.train(batch_in, batch_label)\n",
    "        print('{}/{} epoch, cost : {}'.format(epoch+1, total_epoch, cost))\n",
    "        \n",
    "    save_path = saver.save(sess, 'model_drive') # 모델 저장\n",
    "    #saver.save(sess, \"my_test_model\", global_step=1000)\n",
    "    print('> 학습완료, 모델의 파라미터가 {} 에 저장됨.'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'observation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-93ff0d2f8b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCVHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdata_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;31m# 파일을 열어서 저장 및 불러오기. 텍스트 파일다루기. or binary 파일로\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8231cc5bd2c0>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# 동시에 초기화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# ** 통신필요 **\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'observation' is not defined"
     ]
    }
   ],
   "source": [
    "# 본격 실시간 학습\n",
    "# 모델 파라미터 load, 학습 데이터 load\n",
    "\n",
    "data_base = h5py.File('data_base.h5', 'a') # 학습데이터\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('> 터틀봇 실시간 구동시작.')\n",
    "    saver.restore(sess, save_path)\n",
    "    print('> 모델의 파라미터가 로드 됨. {}'.format(save_path))\n",
    "    observation = env.reset(0) # env 초기화\n",
    "    images_to_add = []\n",
    "    labels_to_add = []\n",
    "    print('> running...')\n",
    "    \n",
    "    while(False):\n",
    "        processed_image = helper.preprocess_frame(observation)\n",
    "        key = env.recv_command_fromhuman()\n",
    "\n",
    "        if(key):\n",
    "            action = env.convert_to_command(key) # command --> action\n",
    "            images_to_add.append(processed_image) # input 데이터 추가\n",
    "            labels_to_add.appedn(action) # label 데이터 추가\n",
    "        else:\n",
    "            policy = model.policy(processed_image)\n",
    "            print('[debug] policy shape : {}'.format(policy))\n",
    "            action = np.array(len(label))\n",
    "            argmax = np.argmax(policy) # CNN --> policy --> action\n",
    "            action[argmax] = 1\n",
    "\n",
    "        observation = env.step(action)\n",
    "        \n",
    "        # 키보드로 종료 커맨드 내리면 일단 종료하고\n",
    "        # 터틀봇 끄고 / 학습 / 파라미터 저장\n",
    "        if(getkey()):\n",
    "            print('> 터틀봇 구동 종료.')\n",
    "            # 데이터 추가\n",
    "            print('> data aggregating...')\n",
    "            base_image_data = data_base['image']\n",
    "            base_label_data = data_base['label']\n",
    "            new_image_data = base_image_data + images_to_add\n",
    "            new_label_data = base_label_data + labels_to_add\n",
    "            \n",
    "            data_base['image'] = new_image_data\n",
    "            data_base['label'] = new_label_data\n",
    "            \n",
    "            # 학습할 데이터 할당\n",
    "            batch_in = new_image_data\n",
    "            batch_label = new_label_data\n",
    "            \n",
    "            # 학습\n",
    "            total_epoch = 1\n",
    "            print('> 재학습 중...')\n",
    "            for epoch in range(total_epoch):\n",
    "                model.train(batch_in, batch_label)\n",
    "                print('{}/{} epoch, cost : {}'.format(epoch+1, total_epoch, cost))\n",
    "                \n",
    "            saver.save(sess, save_path)\n",
    "            print('> 학습완료, 모델의 파라미터가 {} 에 저장'.format(save_path))\n",
    "            break\n",
    "\n",
    "data_base.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
