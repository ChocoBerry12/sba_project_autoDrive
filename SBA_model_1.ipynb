{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitation Learning 모델 1\n",
    "---\n",
    "## Description\n",
    "> SBA 5 조 스마트팩토리 자율주행을 위한 학습 프로그램. vanilla DAgger 모델. \n",
    "\n",
    "## todo\n",
    "* [x] 모듈 1 구현\n",
    "* [ ] 전처리 방법 다양화\n",
    "* [x] 모듈 2 구현\n",
    "* [ ] 모듈 3 구현\n",
    "* [ ] pickle 등으로 로컬에 데이터 저장\n",
    "\n",
    "## 링크\n",
    "* [PEP8 코딩준수](https://kongdols-room.tistory.com/18)\n",
    "* [openCV 가이드](https://opencv-python.readthedocs.io/en/latest/doc/02.videoStart/videoStart.html)\n",
    "* [프로그레스 바 구현](https://wikidocs.net/13977)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습데이터 생성 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class DataCollector:\\n    def __init__(self):\\n        pass'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class DataCollector:\n",
    "    def __init__(self):\n",
    "        pass'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProducer:\n",
    "    def __init__(self, width=320, height=240):\n",
    "        self.observation = [] # 전처리된 영상 데이터 np 원본\n",
    "        self.label = [] # 라벨링 데이터, observation 과 같은 크기\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        print('> data producer 생성. ')\n",
    "        print('> 가로 : {}, 세로 : {}'.format(width, height))\n",
    "        print('-'*50)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '가로 : {}, 세로 : {}'.format(self.width, self.height)\n",
    "    \n",
    "    def produce_observation(self, file=None):\n",
    "        # observation 을 생성하는 메서드\n",
    "        \n",
    "        if(file == None):\n",
    "            # 재생할 원본영상이 없으면 실시간으로 카메라 영상 재생\n",
    "            # 여기서는 노트북의 로컬카메라\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            cap.set(3, self.width)\n",
    "            cap.set(4, self.height)\n",
    "        else:\n",
    "            # 파일로부터 원본영상을 받아 재생\n",
    "            # 처음부터 전처리한 영상을 안만드는 이유는\n",
    "            # 하나의 원본으로부터 다양한 전처리 작업을 한 결과을 얻기 위함\n",
    "            cap = cv2.VideoCapture(file)\n",
    "        \n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if(ret):\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                ret_bin, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "                #cv2.imshow('frame', gray)\n",
    "                cv2.imshow('binary', binary)\n",
    "                self.observation.append(binary)\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print('> observation 데이터 생성완료, 원본 프레임 수 : {}'.format(len(self.observation)))\n",
    "        print('-'*50)\n",
    "    \n",
    "    def produce_label(self, video, delay=10):\n",
    "        # 외부에서 만든 영상파일을 받아 수동으로 라벨링을 하는 메서드\n",
    "        # 수동으로 라벨링하는 과정을 observation 구하는 것과 분리함.\n",
    "        # 다양한 라벨링을 테스트하기 위함\n",
    "        # one_hot encoding 형태\n",
    "        self.label = []\n",
    "        command = [0,1,0]\n",
    "        cap = cv2.VideoCapture(video)        \n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if(ret):\n",
    "                key = cv2.waitKey(delay) & 0xFF\n",
    "                if(key == ord('q')):\n",
    "                    break\n",
    "                elif(key == ord('a')):\n",
    "                    command = [1,0,0]\n",
    "                elif(key == ord('d')):\n",
    "                    command = [0,0,1]\n",
    "                elif(key == ord('w')):\n",
    "                    command = [0,1,0]\n",
    "                \n",
    "                self.label.append(command)\n",
    "                cv2.putText(frame, 'command : {}'.format(command), (10, 30), cv2.FONT_HERSHEY_COMPLEX, .5, (0,0,255), 1)\n",
    "                cv2.imshow('debug', frame)\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print('> label 데이터 생성완료, label 수 : {}'.format(len(self.label)))\n",
    "        print('-'*50)\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # 외부에서 영상을 만들기위해 원본을 제공\n",
    "        video_data = copy.deepcopy(self.observation)\n",
    "        print('> 전처리 영상 복사완료 - 프레임 수: {}'.format(len(self.observation)))\n",
    "        print('-'*50)\n",
    "        return video_data\n",
    "    \n",
    "    def get_label(self):\n",
    "        # 라벨 데이터를 제공하는 메서드\n",
    "        label_data = copy.deepcopy(self.label)\n",
    "        print('> 라벨 데이터 복사완료 - 라벨 수: {}'.format(len(self.label)))\n",
    "        return label_data\n",
    "    \n",
    "    def get_database(self):\n",
    "        # observation - label 데이터 쌍을 data 학습데이터로 생성하는 메서드\n",
    "        # CNN 에 사용하기 위해 4 dim 으로 reshape 한 후 최종 학습데이터 반환\n",
    "        print('> 영상 프레임 수 : {}, 라벨 프레임 수 : {}, 부족한 라벨 수: {}'.format(len(self.observation), len(self.label), len(self.observation) - len(self.label)))\n",
    "        print('> {} 프레임 학습 데이터 생성완료.'.format(len(self.label)))\n",
    "        print('-'*50)\n",
    "        selected_ob = self.observation[:len(self.label)]\n",
    "        selected_ob = np.array(selected_ob)\n",
    "        selected_ob = selected_ob.reshape([-1,240,320,1])\n",
    "        return zip(selected_ob, self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> data producer 생성. \n",
      "> 가로 : 320, 세로 : 240\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dp = DataProducer() # 학습데이터 생성기 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> observation 데이터 생성완료, 원본 프레임 수 : 74\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dp.produce_observation() # raw 영상으로부터 전처리영상 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
    "fps = 25.0\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (320,240), 0) # 세밀한 컨트롤을 위해 프레임 늘리기 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 전처리 영상 복사완료 - 프레임 수: 74\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 영상원본을 동영상파일로 저장\n",
    "copied_observation = dp.get_observation()\n",
    "for f in range(len(copied_observation)):\n",
    "    frame = copied_observation[f]\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> label 데이터 생성완료, label 수 : 74\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dp.produce_label('output.avi', delay=50) # 만들어진 동영상파일을 가지고 수동으로 라벨링하여 라벨을 프레임별로 따로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 영상 프레임 수 : 74, 라벨 프레임 수 : 74, 부족한 라벨 수: 0\n",
      "> 74 프레임 학습 데이터 생성완료.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = list(dp.get_database()) # observation - label 모음 학습데이터를 획득한다.\n",
    "for i, d in enumerate(data):\n",
    "    #shaped = np.reshape(d[0],[-1,240,320,1])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 신경망 학습 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow 관련\n",
    "* feed 데이터는 기본 자료형, numpy 가능. tensor 는 순수한 값이 아닌 연산노드이므로 계산불가\n",
    "* `squeeze()`, `expand_dim()` 으로 dimension 조절\n",
    "* one-hot 인코딩 데이터 배열을 비교할 때는 `np.all(a==b)`\n",
    "* logit 과 sigmoid, softmax 의 관계는 역함수 관계.\n",
    "* `softmax_cross_entropy_with_logits_v2` 는 네트워크의 출력인 logit 을 그대로 때려박아서 분류결과를 내놓는다.\n",
    "* softmax(logit) 하고 corssentropy 를 적용하는 작업을 합친것임. logit 은 softmax 의 역함수이므로\n",
    "---\n",
    "### TODO\n",
    "* [ ] 네트워크 변형하며 성능 테스트\n",
    "* [ ] label 데이터의 형태 변형하여 테스트 - 현재는 3 개 카테고리의 분류문제인데 너무 단순하고 practical 하지 않음\n",
    "* [ ] 실제로는 steering angle 에 대응하는 floating number 로 regression output 이 필요\n",
    "* [ ] 검증하는 코드 작성하기\n",
    "* [ ] CPU 점유율 너무높음. AWS 쓰게 해줘 ㅠㅠ\n",
    "* Imitation Learning 을 위해 output 은 더 세밀한 action 이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, h, w, sess):\n",
    "        self.size_h = h\n",
    "        self.size_w = w\n",
    "        self.sess = sess\n",
    "        self.model = self.make_model()\n",
    "    \n",
    "    def make_model(self):\n",
    "        # 모델\n",
    "        self.observation = tf.placeholder(shape=[None, self.size_h, self.size_w, 1], dtype=tf.float32) # 이미지 데이터\n",
    "        self.label = tf.placeholder(shape=[None, 3], dtype=tf.int16) # 라벨 데이터\n",
    "        \n",
    "        self.w_in = tf.Variable(tf.random_normal([5,5,1,8], stddev=.01)) # conv 1 가중치\n",
    "        self.l1 = tf.nn.conv2d(self.observation, self.w_in, strides=[1,1,1,1], padding='SAME')\n",
    "        self.l1 = tf.nn.relu(self.l1)\n",
    "        self.l1 = tf.nn.max_pool(self.l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        self.w_out = tf.Variable(tf.random_normal(shape=[self.size_w//2*self.size_h//2*8, 3], stddev=.01))\n",
    "        self.b = tf.Variable(tf.random_normal([3]))\n",
    "        self.h_flat = tf.reshape(self.l1, [-1, self.size_w//2*self.size_h//2*8])\n",
    "        \n",
    "        self.output = tf.matmul(self.h_flat, self.w_out) + self.b\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.output, labels=self.label))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(self.cost)\n",
    "        print('> 모델 생성 완료')\n",
    "        \n",
    "    def train(self, batch_in, batch_label):\n",
    "        # 학습시행.\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict={self.observation:batch_in, self.label:batch_label})\n",
    "        return cost\n",
    "    \n",
    "    def test(self, d, y):\n",
    "        # 길을 잘 인식하는지 테스트.\n",
    "        # 테스트 데이터 셋을 미리 저장해놓고 검증하는 메서드\n",
    "        # 시각화 필요\n",
    "        out = self.sess.run(self.output, feed_dict={self.observation:d})\n",
    "        idx = np.argmax(out, axis=1)\n",
    "        one_hot = np.zeros_like(out)\n",
    "        cnt = 0\n",
    "        for i, arr in enumerate(one_hot):\n",
    "            arr[idx[i]] = 1\n",
    "            if(np.all(arr == y[i])):\n",
    "                cnt += 1\n",
    "        \n",
    "        accuracy = cnt / len(d)\n",
    "        return accuracy\n",
    "    \n",
    "    def test_live(self):\n",
    "        # 실시간으로 길을 잘 인식하는지 테스트하는 메서드.\n",
    "        out = self.sess.run(self.output, feed_dict={self.observation:d})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 총 데이터 갯수 : 74, 학습 데이터 갯수 : 37, 검증 데이터 갯수 : 37\n",
      "start\n",
      "> 모델 생성 완료\n",
      "1 epoch, cost : 26.682661056518555\n",
      "2 epoch, cost : 366.2832946777344\n",
      "3 epoch, cost : 183.99240112304688\n",
      "4 epoch, cost : 34.15765380859375\n",
      "5 epoch, cost : 0.3319648504257202\n",
      "6 epoch, cost : 11.845327377319336\n",
      "7 epoch, cost : 4.226559638977051\n",
      "8 epoch, cost : 0.5367381572723389\n",
      "9 epoch, cost : 0.043232642114162445\n",
      "10 epoch, cost : 0.019332807511091232\n",
      "11 epoch, cost : 0.07625644654035568\n",
      "12 epoch, cost : 0.120908722281456\n",
      "13 epoch, cost : 0.1279595047235489\n",
      "14 epoch, cost : 0.12072278559207916\n",
      "15 epoch, cost : 0.1053871214389801\n",
      "16 epoch, cost : 0.08260931819677353\n",
      "17 epoch, cost : 0.058390360325574875\n",
      "18 epoch, cost : 0.03774141147732735\n",
      "19 epoch, cost : 0.02301478385925293\n",
      "20 epoch, cost : 0.013968897983431816\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터\n",
    "learning_rate = .001\n",
    "total_epoch = 20\n",
    "\n",
    "# train data, test data 절반씩 나누기\n",
    "batch_in_train = [data[i][0] for i in range(len(data)//2)]\n",
    "batch_label_train = [data[i][1] for i in range(len(data)//2)]\n",
    "batch_in_test = [data[i][0] for i in range(len(data)//2, len(data))]\n",
    "batch_label_test = [data[i][1] for i in range(len(data)//2, len(data))]\n",
    "\n",
    "print('> 총 데이터 갯수 : {}, 학습 데이터 갯수 : {}, 검증 데이터 갯수 : {}'.format(len(data), len(batch_in_train), len(batch_in_test)))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('start')\n",
    "    model = CNN(240, 320, sess)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(total_epoch):\n",
    "        cost = model.train(batch_in_train, batch_label_train)\n",
    "        print('{} epoch, cost : {}'.format(epoch+1, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 실시간 Data Aggregatioin 모듈"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
